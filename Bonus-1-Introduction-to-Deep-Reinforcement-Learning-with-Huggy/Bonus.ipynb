{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a37c9b1f",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#How-Huggy-works?\" data-toc-modified-id=\"How-Huggy-works?-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>How Huggy works?</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-State-Space,-what-Huggy-perceives.\" data-toc-modified-id=\"The-State-Space,-what-Huggy-perceives.-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>The State Space, what Huggy perceives.</a></span></li><li><span><a href=\"#The-Action-Space,-what-moves-Huggy-can-perform\" data-toc-modified-id=\"The-Action-Space,-what-moves-Huggy-can-perform-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>The Action Space, what moves Huggy can perform</a></span></li><li><span><a href=\"#The-Reward-Function\" data-toc-modified-id=\"The-Reward-Function-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>The Reward Function</a></span></li><li><span><a href=\"#Train-Huggy\" data-toc-modified-id=\"Train-Huggy-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Train Huggy</a></span></li></ul></li><li><span><a href=\"#Train-Huggy\" data-toc-modified-id=\"Train-Huggy-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Train Huggy</a></span></li><li><span><a href=\"#Play-with-Huggy\" data-toc-modified-id=\"Play-with-Huggy-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Play with Huggy</a></span></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95182c18",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efa848b",
   "metadata": {},
   "source": [
    "We will teach Huggy the Dog to fetch the stick and then play with him [directly in our browser üê∂](https://huggingface.co/spaces/ThomasSimonini/Huggy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ae673",
   "metadata": {},
   "source": [
    "# How Huggy works?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13e7360",
   "metadata": {},
   "source": [
    "<b>Huggy</b> is a Deep Reinforcement Learning environment made by Hugging Face\n",
    "\n",
    "In this environment we aim to <b>train Huggy to fetch the stick we throw. This means he needs to move correctly toward the stick.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0381ac",
   "metadata": {},
   "source": [
    "## The State Space, what Huggy perceives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d6f661",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Huggy doesn't \"see\" his environment</span>. <span style=\"color:green\">Instead, we provide him information about the environment:</span>\n",
    "- The target (stick) position\n",
    "- The relative position between himself and the target\n",
    "- The orientation of his legs.\n",
    "\n",
    "Given all this information, Huggy can <b>use his policy to determine which action to take next to fulfill his goal</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c331b3",
   "metadata": {},
   "source": [
    "## The Action Space, what moves Huggy can perform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21927bad",
   "metadata": {},
   "source": [
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/huggy-action.jpg\" style=\"width:500px;\" title=\"Huggy Action\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41563c4b",
   "metadata": {},
   "source": [
    "<b>Joint motors drive Huggy‚Äôs legs</b>. This means that to get the target, Huggy needs to <b>learn to rotate the joint motors of each of his legs correctly so he can move</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732405e8",
   "metadata": {},
   "source": [
    "## The Reward Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e2b283",
   "metadata": {},
   "source": [
    "The reward function is designed so that <b>Huggy will fulfill his goal: fetch the stick.</b>\n",
    "\n",
    "Here, <span style=\"color:blue\">our goal is that Huggy goes towards the stick but without spinning too much</span>. Hence, our reward function must translate this goal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594808f5",
   "metadata": {},
   "source": [
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/reward.jpg\" style=\"width:500px;\" title=\"Huggy Reward\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081caf32",
   "metadata": {},
   "source": [
    "- <i>Orientation bonus</i>: we <b>reward him for getting close to the target.</b>\n",
    "- <i>Time penalty</i>: a fixed-time penalty given at every action to <b>force him to get to the stick as fast as possible.</b>\n",
    "- <i>Rotation penalty</i>: we penalize Huggy if <b>he spins too much and turns too quickly.</b>\n",
    "- <i>Getting to the target reward</i>: we reward Huggy for <b>reaching the target.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c499e58",
   "metadata": {},
   "source": [
    "## Train Huggy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b4533a",
   "metadata": {},
   "source": [
    "Huggy aims <b>to learn to run correctly and as fast as possible toward the goal</b>. To do that, at every step and given the environment observation, he needs to decide how to rotate each joint motor of his legs to move correctly (not spinning too much) and towards the goal.\n",
    "\n",
    "The training loop looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdf1778",
   "metadata": {},
   "source": [
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/huggy-loop.jpg\" style=\"width:700px;\" title=\"Huggy Training Loop\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e22a22d",
   "metadata": {},
   "source": [
    "To train the Huggy to fetch the stick in the training environment, we‚Äôre going to use [MLAgents](https://github.com/Unity-Technologies/ml-agents). Don‚Äôt worry if you have never used it before. In this unit we‚Äôll use Google Colab to train Huggy, and then you‚Äôll be able to load your trained Huggy and play with him directly in the browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38a3afa",
   "metadata": {},
   "source": [
    "# Train Huggy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b58263",
   "metadata": {},
   "source": [
    "- My [model repo](https://huggingface.co/prasanthntu/ppo-Huggy) in hugging face    \n",
    "    - It can even be found under the this [spaces](https://huggingface.co/spaces/ThomasSimonini/Huggy)\n",
    "- Source code for building the model: \n",
    "    - [Google Colab stored in Google Drive](https://colab.research.google.com/drive/1s0ZVkO95QAIpJLASYDpTj54c9mWCe7aE?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4324fd7",
   "metadata": {},
   "source": [
    "# Play with Huggy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd7a4fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T05:36:31.607611Z",
     "start_time": "2023-08-17T05:36:31.595820Z"
    }
   },
   "source": [
    "Now that we‚Äôve trained Huggy and pushed it to the Hub. We will be able to play with him ‚ù§Ô∏è\n",
    "\n",
    "For this step it‚Äôs simple:\n",
    "\n",
    "- Open the Huggy game in your browser: https://huggingface.co/spaces/prasanthntu/Huggy\n",
    "- Click on Play with my Huggy model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282150b8",
   "metadata": {},
   "source": [
    "1. In step 1, choose your model repository which is the model id (in my case prasanthntu/ppo-Huggy).\n",
    "\n",
    "2. In step 2, choose which model you want to replay:\n",
    "\n",
    "- We have multiple ones, since we saved a model every 500000 timesteps.\n",
    "- But if we want the most recent one, we choose `Huggy.onnx`\n",
    "\n",
    "üëâ It‚Äôs good to <b>try with different model checkpoints to see the improvement of the agent.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8857fe72",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2165f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai_related",
   "language": "python",
   "name": "fastai_related"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "796px",
    "left": "26px",
    "top": "0px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
