{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc5da35",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Optuna-Tutorial\" data-toc-modified-id=\"Optuna-Tutorial-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Optuna Tutorial</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-theory-behind-Hyperparameter-tuning\" data-toc-modified-id=\"The-theory-behind-Hyperparameter-tuning-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>The theory behind Hyperparameter tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Notes-from-Video\" data-toc-modified-id=\"Notes-from-Video-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Notes from Video</a></span></li><li><span><a href=\"#&quot;N-vs-B/N&quot;-Tradeoff\" data-toc-modified-id=\"&quot;N-vs-B/N&quot;-Tradeoff-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>\"N vs B/N\" Tradeoff</a></span></li><li><span><a href=\"#Samplers-(Search-algo)\" data-toc-modified-id=\"Samplers-(Search-algo)-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Samplers (Search algo)</a></span></li><li><span><a href=\"#Schedulers-(Prunner)\" data-toc-modified-id=\"Schedulers-(Prunner)-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Schedulers (Prunner)</a></span></li><li><span><a href=\"#Optuna-demo---HP-Tuning-Steps\" data-toc-modified-id=\"Optuna-demo---HP-Tuning-Steps-2.1.5\"><span class=\"toc-item-num\">2.1.5&nbsp;&nbsp;</span>Optuna demo - HP Tuning Steps</a></span><ul class=\"toc-item\"><li><span><a href=\"#Search-space\" data-toc-modified-id=\"Search-space-2.1.5.1\"><span class=\"toc-item-num\">2.1.5.1&nbsp;&nbsp;</span><b>Search space</b></a></span></li><li><span><a href=\"#RL-Objective-Function\" data-toc-modified-id=\"RL-Objective-Function-2.1.5.2\"><span class=\"toc-item-num\">2.1.5.2&nbsp;&nbsp;</span><b>RL Objective Function</b></a></span></li><li><span><a href=\"#Choose-sampler,-pruner-and-launch-the-study\" data-toc-modified-id=\"Choose-sampler,-pruner-and-launch-the-study-2.1.5.3\"><span class=\"toc-item-num\">2.1.5.3&nbsp;&nbsp;</span><b>Choose sampler, pruner and launch the study</b></a></span></li></ul></li><li><span><a href=\"#Common-pitfalls\" data-toc-modified-id=\"Common-pitfalls-2.1.6\"><span class=\"toc-item-num\">2.1.6&nbsp;&nbsp;</span>Common pitfalls</a></span></li><li><span><a href=\"#Recap\" data-toc-modified-id=\"Recap-2.1.7\"><span class=\"toc-item-num\">2.1.7&nbsp;&nbsp;</span>Recap</a></span></li></ul></li><li><span><a href=\"#Optuna-tutorial-2\" data-toc-modified-id=\"Optuna-tutorial-2-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Optuna tutorial 2</a></span></li></ul></li><li><span><a href=\"#Hands-on\" data-toc-modified-id=\"Hands-on-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Hands-on</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ebc496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T11:45:57.298618Z",
     "start_time": "2023-09-07T11:45:57.280371Z"
    }
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238838cb",
   "metadata": {},
   "source": [
    "One of the most critical tasks in Deep Reinforcement Learning is to find a good set of training hyperparameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08188e28",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"https://raw.githubusercontent.com/optuna/optuna/master/docs/image/optuna-logo.png\" style=\" width:200px; padding: 10px 20px;\" title=\"Optuna Loog\">\n",
    "\n",
    "[Optuna]() is a library that helps you to automate the search. In this Unit, we’ll study <b>a little bit of the theory behind automatic hyperparameter tuning.</b> We’ll first try to optimize the parameters of the DQN studied in the last unit manually. We’ll then <b>learn how to automate the search using Optuna.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523954a0",
   "metadata": {},
   "source": [
    "# Optuna Tutorial\n",
    "\n",
    "The content below comes from [Antonin’s Raffin ICRA 2022 presentations](https://araffin.github.io/tools-for-robotic-rl-icra2022/), he’s one of the founders of Stable-Baselines and RL-Baselines3-Zoo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e3dd67",
   "metadata": {},
   "source": [
    "## The theory behind Hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b221489",
   "metadata": {},
   "source": [
    "[![Automatic Hyperparameter Optimization @ ICRA 22 | Tools for Robotic RL 6/8](http://img.youtube.com/vi/AidFTOdGNFQ/0.jpg)](http://www.youtube.com/watch?v=AidFTOdGNFQ \"Automatic Hyperparameter Optimization @ ICRA 22 | Tools for Robotic RL 6/8\")\n",
    "<span style=\"font-size:small\"><center><i>Automatic Hyperparameter Optimization @ ICRA 22 | Tools for Robotic RL 6/8.</i></center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec33f69",
   "metadata": {},
   "source": [
    "### Notes from Video\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566ffc26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T07:28:25.049226Z",
     "start_time": "2023-09-18T07:28:25.036176Z"
    }
   },
   "source": [
    "<b>Motivation</b>\n",
    "- Fair comaparison with baselines \n",
    "    - While doing research, and we want to compare to baseline, usually, we tune our own methods a lot. But, to be fair, we also need to tune other baseline. \n",
    "- Automatic tuning (no more grad student descent)\n",
    "    - Lot of time spent wathching different metrics and trying different configs\n",
    "- Improve performance/training time\n",
    "    - Reach given performance in given amount of time (e.g., 15 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff66b81",
   "metadata": {},
   "source": [
    "<b>Outline</b>\n",
    "\n",
    "1. <b>Hyperparameter Optimization: \"b vs B/n\" tradeoff</b>\n",
    "    - Trade-off between No. of configs vs. Budget<br><br>\n",
    "    \n",
    "2. <b>Samplers</b>\n",
    "    - Different algos <br><br>\n",
    "3. <b>Schedulers</b>\n",
    "    - Different algos <br><br>\n",
    "4. <b>In Practice (Optuna)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1413d8",
   "metadata": {},
   "source": [
    "### \"N vs B/N\" Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e47ee58",
   "metadata": {},
   "source": [
    "<img src=\"attachments/n-vs-bn-tradeoff.png\" style=\"width:700px;\" title=\"N vs B/N tradeoff\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66137cce",
   "metadata": {},
   "source": [
    "Reduce budget (or remove) the less promising trials, and give more budget (allocating more resources) to more promising trials as the time progress.\n",
    "\n",
    "\n",
    "Two main components in hyperparameter optimization:\n",
    "1. <b>Sampler</b> (search algo): Decides which config we need to try\n",
    "2. <b>Pruner</b> (scheduler): Decides when to stop the trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ac1481",
   "metadata": {},
   "source": [
    "### Samplers (Search algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfa9636",
   "metadata": {},
   "source": [
    "<img src=\"attachments/performance-landscape.png\" style=\"width:700px;\" title=\"Performance Landscape\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7edbcca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T07:46:28.883448Z",
     "start_time": "2023-09-18T07:46:28.878613Z"
    }
   },
   "source": [
    "We don't have this Performance Landscape in advance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbea54b",
   "metadata": {},
   "source": [
    "<img src=\"attachments/grid-search.png\" style=\"width:800px;\" title=\"Grid Search\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79d8fa",
   "metadata": {},
   "source": [
    "What we have been doign so far?\n",
    "- Discretizing the parameter search space, but this can be quite tricky to reach optimal hyperparams, beacuse\n",
    "    - <span style=\"color:red\">we do not know how to discretize the search space in advance</span>\n",
    "    - <span style=\"color:red\">we end up allocating same budget for both important and unimportant paramater</span>\n",
    "    - <span style=\"color:red\">it scales very poorly (the search space explodes) as the n_params increases</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49bb8c3",
   "metadata": {},
   "source": [
    "<img src=\"attachments/grid-search-vs-random-search.png\" style=\"width:800px;\" title=\"Grid Search vs. Random Search\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e345e2",
   "metadata": {},
   "source": [
    "In the world of hyper parameter optimization, grid search is not used as a baseline anymore. Instead, a more complicated <b>random search</b> is used. Besides, random search is not affected by discretization.\n",
    "\n",
    "Can we do better than random search? Yes, we can do \n",
    "- <b>Bayesian Optimization</b> or \n",
    "    - Gaussian Process\n",
    "    - Tree of Parzen Estimators\n",
    "- <b>Black Box Optimization</b>\n",
    "    - Evolution Strategies\n",
    "    - Practice Swarm Optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712c1af5",
   "metadata": {},
   "source": [
    "<img src=\"attachments/bayesian-optimization.png\" style=\"width:800px;\" title=\"Bayesian optimization\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496fdf01",
   "metadata": {},
   "source": [
    "Learn a Surrogate model. It's a model that given the a set of parameter, it will estimate the performance (black line in the fig above) we will get. This model come with some uncertainty (blue area in the fig above).\n",
    "\n",
    "How it works?\n",
    "- What we want to achieve is maximum performance (the black dotted line) which we don't know \n",
    "- Starts with a random config that we sample (a.k.a an observation as show in fig) and the uncertainty will go smaller near the observation\n",
    "- Assemble the points that is the most promising one (by iteratively taking the surrogate model outputs and uncertainty into the acquistion function thaht tells where we should sample to may be get the best results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f35bb",
   "metadata": {},
   "source": [
    "### Schedulers (Prunner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac6fadc",
   "metadata": {},
   "source": [
    "Few popular scheduler algos are\n",
    "- Median pruner\n",
    "- Successive halving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ac8cf",
   "metadata": {},
   "source": [
    "<b>Median Pruner</b>\n",
    "- Simple heuristics\n",
    "- Used in [Google Vizier](https://github.com/google/vizier)\n",
    "- Prune if the trial's intermediate result is worse than median of intermediate results of previous trials at the same step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f848211",
   "metadata": {},
   "source": [
    "<b>Successive Halving</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24f564f",
   "metadata": {},
   "source": [
    "<img src=\"attachments/successive-halving.png\" style=\"width:800px;\" title=\"Successive halving\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7c0ff1",
   "metadata": {},
   "source": [
    "### Optuna demo - HP Tuning Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e5d694",
   "metadata": {},
   "source": [
    "- Define the search space\n",
    "    - Params we are going to optimise and their boundaries\n",
    "- Define the objective function\n",
    "    - What we want to optimise? In RL, we optimise for preformance. But, we may optimise for energy efficiency, fast training, etc.\n",
    "- Choose a sampler and pruner\n",
    "- Get a coffee/ nap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaa8735",
   "metadata": {},
   "source": [
    "#### <b>Search space</b>\n",
    "- In optuna, there are 3 main types\n",
    "    1. Categorical variables \n",
    "    2. Integers\n",
    "    3. Floats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a5dc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T23:12:33.611360Z",
     "start_time": "2023-09-18T23:12:33.602372Z"
    }
   },
   "source": [
    "<img src=\"attachments/search-space-example.png\" style=\"width:650px;\" title=\"Search space example\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5376379",
   "metadata": {},
   "source": [
    "#### <b>RL Objective Function</b>\n",
    "- Two parts\n",
    "    1. Evaluation part\n",
    "        - Evaluating periodically the trial and sending the report to Optune. Optuna tells whether we should prune or continue training based on the eval performance\n",
    "    2. ...\n",
    "        - Defining the model, sampling the hyperparameter, training the model, and sending back to optuna to find the performance. Steps involved are\n",
    "        - Sample hyperparameters using `sample_ppo_params`\n",
    "        - Create/Instantiate the RL model/algo using `PPO(...)`\n",
    "        - Create/Instantiate the callback that will periodically evaluate and report the trial performance using `...`\n",
    "        - Train the model using `model.learn(...)`\n",
    "        - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cd7dc4",
   "metadata": {},
   "source": [
    "<img src=\"attachments/rl-objective-function-1-of-2.png\" style=\"width:650px;\" title=\"RL objective function (1/2)\">\n",
    "<img src=\"attachments/rl-objective-function-2-of-2.png\" style=\"width:700px;\" title=\"RL objective function (2/2)\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ab13e0",
   "metadata": {},
   "source": [
    "#### <b>Choose sampler, pruner and launch the study</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb35cf26",
   "metadata": {},
   "source": [
    "- Select a sampler, \n",
    "    - e.g., Bayesian optimization using `TPESampler(...)`. \n",
    "- Select a pruner\n",
    "    - e.g., `MedianPruner(...)`\n",
    "- Create the optuna study\n",
    "    - e.g., We want to maximise the cumulative reward, so `optuna.create(..., direction=\"maximize\")`\n",
    "- Run in parallel\n",
    "- Get the best result (trial with best type of parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb5469",
   "metadata": {},
   "source": [
    "<img src=\"attachments/choose-sampler-pruner-launch-study.png\" style=\"width:700px;\" title=\"Choose sampler, pruner and launch the study!\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68ddbad",
   "metadata": {},
   "source": [
    "### Common pitfalls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eaaddd",
   "metadata": {},
   "source": [
    "- HP optimization not needed (train longer first)\n",
    "- Noisy evaluation: Multiple eval \n",
    "    - Different random seed will provide different results\n",
    "- Search space too small/wide\n",
    "- Slow optimization: Smaller budget\n",
    "- Training not stable: Manual tweaks\n",
    "    - Reducing the learning rate, or augmenting the replay buffer size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9303ea3",
   "metadata": {},
   "source": [
    "### Recap\n",
    "\n",
    "- Use automatic tuning when possible/needed\n",
    "- Automatic tuning = sampler + pruner + objective function\n",
    "- Do not use grid search\n",
    "- Common pitfalls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5dd0a",
   "metadata": {},
   "source": [
    "## Optuna tutorial 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f891e38",
   "metadata": {},
   "source": [
    "[![Hyperparameter Tuning with Optuna Notebook @ ICRA 22 | Tools for Robotic RL 7/8\n",
    "](http://img.youtube.com/vi/ihP7E76KGOI/0.jpg)](http://www.youtube.com/watch?v=ihP7E76KGOI \"Hyperparameter Tuning with Optuna Notebook @ ICRA 22 | Tools for Robotic RL 7/8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f53f45",
   "metadata": {},
   "source": [
    "- My [source code](https://colab.research.google.com/drive/1dKECP2z6Qqj2Ci3iP0n6LOFkEH7XhO6c?usp=sharing) in Google Colab stored in Google Drive for building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd78318c",
   "metadata": {},
   "source": [
    "# Hands-on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213a81e6",
   "metadata": {},
   "source": [
    "Now that you’ve learned to use Optuna, here are some ideas to apply what you’ve learned:\n",
    "\n",
    "1️⃣ <b>Beat your LunarLander-v2 agent results</b>, by using Optuna to find a better set of hyperparameters. You can also try with another environment, such as MountainCar-v0 and CartPole-v1.\n",
    "\n",
    "2️⃣ <b>Beat your SpaceInvaders agent results.</b>\n",
    "\n",
    "By doing this, you’ll see how valuable and powerful Optuna can be in training better agents.\n",
    "\n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5395a671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai_related",
   "language": "python",
   "name": "fastai_related"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "512px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
