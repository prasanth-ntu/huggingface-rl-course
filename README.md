# Hugging Face "Deep Reinforcement Learning" Course

- Course: [Link](https://huggingface.co/learn/deep-rl-course/unit0/introduction)
- Blog: [Link](https://discuss.huggingface.co/)
- Discord
  - `#rl-announcements`: where we give the latest information about the course.
  - [`#rl-discussions`]((https://discord.com/channels/879548962464493619/915190889243103282)): where you can chat about RL and share information.
  - `#rl-study-group`: where you can create and join study groups.
  - `#rl-i-made-this`: where you can share your projects and models.
mkdir 
- Check course progress: [Link](https://huggingface.co/spaces/ThomasSimonini/Check-my-progress-Deep-RL-Course)
- Leaderboard: [Link](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)
# My Content
- [Unit 0. Welcome to the course](./0-Welcome-to-the-course/)
- [Unit 1. Introduction to Deep Reinforcement Learning](./1-Introduction-to-Deep-Reinforcement-Learning/)
  - [1.1 Introduction](./1-Introduction-to-Deep-Reinforcement-Learning/1.1%20to%201.13.ipynb)
  - [1.2 What is Reinforcement Learning?](./1-Introduction-to-Deep-Reinforcement-Learning/1.1%20to%201.13.ipynb)
  - [1.3 The Reinforcement Learning Framework](./1-Introduction-to-Deep-Reinforcement-Learning/1.1%20to%201.13.ipynb)
  - [1.4  The type of tasks](./1-Introduction-to-Deep-Reinforcement-Learning/1.1%20to%201.13.ipynb)
  - [1.5  The Exploration/ Exploitation tradeoff](./1-Introduction-to-Deep-Reinforcement-Learning/1.1%20to%201.13.ipynb)
  - [1.6  The two main approaches for solving RL problems](./1-Introduction-to-Deep-Reinforcement-Learning/1.1%20to%201.13.ipynb)
  - [1.7  The “Deep” in Deep Reinforcement Learning](./1-Introduction-to-Deep-Reinforcement-Learning/1.1%20to%201.13.ipynb)
  - [1.8 Summary](./1-Introduction-to-Deep-Reinforcement-Learning/1.1%20to%201.13.ipynb)
  - [1.9 Glossary](./1-Introduction-to-Deep-Reinforcement-Learning/1.1%20to%201.13.ipynb)
  - [1.10 Hands-on](./1-Introduction-to-Deep-Reinforcement-Learning/1.1%20to%201.13.ipynb)
  - [1.11 Quiz](./1-Introduction-to-Deep-Reinforcement-Learning/1.11-Quiz.pdf)
  - [1.12 Conclusion](./1-Introduction-to-Deep-Reinforcement-Learning/1.1%20to%201.13.ipynb)
  - [1.13  Additional Readings](./1-Introduction-to-Deep-Reinforcement-Learning/1.1%20to%201.13.ipynb)
- [Bonus Unit 1. Introduction to Deep Reinforcement Learning with Huggy](./Bonus-1-Introduction-to-Deep-Reinforcement-Learning-with-Huggy/)
  - [Introduction](./Bonus-1-Introduction-to-Deep-Reinforcement-Learning-with-Huggy/Bonus.ipynb)
  - [How Huggy works?](./Bonus-1-Introduction-to-Deep-Reinforcement-Learning-with-Huggy/Bonus-1.1-1.2.ipynb)
  - [Train Huggy](./Bonus-1-Introduction-to-Deep-Reinforcement-Learning-with-Huggy/Bonus.ipynb)
  - [Play with Huggy](./Bonus-1-Introduction-to-Deep-Reinforcement-Learning-with-Huggy/Bonus.ipynb)
  - Conclusion
- [Unit 2. Introduction to Q-Learning](./2-Introduction-to-Q-Learning/)
  - [2.1 Introduction](./2-Introduction-to-Q-Learning/2.1-to-2.15.ipynb)
  - [2.2 What is RL? A short recap](./2-Introduction-to-Q-Learning/2.1-to-2.15.ipynb)
  - [2.3 The two types of value-based methods](./2-Introduction-to-Q-Learning/2.1-to-2.15.ipynb)
  - [2.4 The Bellman Equation, simplify our value estimation](./2-Introduction-to-Q-Learning/2.1-to-2.15.ipynb)
  - [2.5 Monte Carlo vs Temporal Difference Learning](./2-Introduction-to-Q-Learning/2.1-to-2.15.ipynb)
  - [2.6 Mid-way Recap](./2-Introduction-to-Q-Learning/2.1-to-2.15.ipynb)
  - [2.7 Mid-way Quiz](./2-Introduction-to-Q-Learning/2.1-to-2.15.ipynb)
  - [2.8 Introducing Q-Learning](./2-Introduction-to-Q-Learning/2.1-to-2.15.ipynb)
  - [2.9 A Q-Learning example](./2-Introduction-to-Q-Learning/2.1-to-2.15.ipynb)
  - [2.10 Q-Learning Recap](./2-Introduction-to-Q-Learning/2.1-to-2.15.ipynb)
  - [2.11 Glossary](./2-Introduction-to-Q-Learning/2.1-to-2.15.ipynb)
  - [2.12 Hands-on](./2-Introduction-to-Q-Learning/2.1-to-2.15.ipynb)
  - [2.13 Q-Learning Quiz](./2-Introduction-to-Q-Learning/2.1-to-2.15.ipynb)
  - [2.14 Conclusion](./2-Introduction-to-Q-Learning/2.1-to-2.15.ipynb)
  - [2.15 Additional Readings](./2-Introduction-to-Q-Learning/2.1-to-2.15.ipynb)
- [Unit 3. Deep Q-Learning with Games](./3-Deep-Q-Learning-with-Atari-games/)
  - [3.1 Introduction](./3-Deep-Q-Learning-with-Atari-games/3.1-to-3.9.ipynb)
  - [3.2 From Q-Learning to Deep Q-Learning](./3-Deep-Q-Learning-with-Atari-games/3.1-to-3.9.ipynb)
  - [3.3 The Deep Q-Network, DQN](./3-Deep-Q-Learning-with-Atari-games/3.1-to-3.9.ipynb)
  - [3.4 The Deep Q Algorithm](./3-Deep-Q-Learning-with-Atari-games/3.1-to-3.9.ipynb)
  - [3.5 Glossary](./3-Deep-Q-Learning-with-Atari-games/3.1-to-3.9.ipynb)
  - [3.6 Hands-on](./3-Deep-Q-Learning-with-Atari-games/3.1-to-3.9.ipynb)
  - [3.7 Quiz](./3-Deep-Q-Learning-with-Atari-games/)
  - [3.8 Conclusion](./3-Deep-Q-Learning-with-Atari-games/3.1-to-3.9.ipynb)
  - [3.9 Additional Readings](./3-Deep-Q-Learning-with-Atari-games/3.1-to-3.9.ipynb)
# Other Contents
- [My Glossary]()

# Todo's
- [x]  Move `unit1.ipynb` from git to google drive as there are some issues in retaining the outputs while storing the google colab in git. Also, add the markdown comments for key hyperparams/configs as they are lost in the saving issue
- [x] Refresh on Q-learning pseudo-code and source-code conceptually
- [ ] The 3 steps in Deep Q-learning (in Unit 3) seems slightly unclear (especially, the 3rd one: Double DQN)
- [ ] Number of state spaces in Atari and LunarLander [Discord link](https://discord.com/channels/879548962464493619/915190889243103282/1148959980561641492)
- [ ] Try optuna for Hopt with LunarLander-v2 or SpaceInvaders (Bonus-Unit-2)